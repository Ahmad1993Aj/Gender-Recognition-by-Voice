{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0feaf4a7",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad4ebe4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"voice.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "41e02774",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>meanfreq</th>\n",
       "      <th>sd</th>\n",
       "      <th>median</th>\n",
       "      <th>Q25</th>\n",
       "      <th>Q75</th>\n",
       "      <th>IQR</th>\n",
       "      <th>skew</th>\n",
       "      <th>kurt</th>\n",
       "      <th>sp.ent</th>\n",
       "      <th>sfm</th>\n",
       "      <th>...</th>\n",
       "      <th>centroid</th>\n",
       "      <th>meanfun</th>\n",
       "      <th>minfun</th>\n",
       "      <th>maxfun</th>\n",
       "      <th>meandom</th>\n",
       "      <th>mindom</th>\n",
       "      <th>maxdom</th>\n",
       "      <th>dfrange</th>\n",
       "      <th>modindx</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.059781</td>\n",
       "      <td>0.064241</td>\n",
       "      <td>0.032027</td>\n",
       "      <td>0.015071</td>\n",
       "      <td>0.090193</td>\n",
       "      <td>0.075122</td>\n",
       "      <td>12.863462</td>\n",
       "      <td>274.402906</td>\n",
       "      <td>0.893369</td>\n",
       "      <td>0.491918</td>\n",
       "      <td>...</td>\n",
       "      <td>0.059781</td>\n",
       "      <td>0.084279</td>\n",
       "      <td>0.015702</td>\n",
       "      <td>0.275862</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.066009</td>\n",
       "      <td>0.067310</td>\n",
       "      <td>0.040229</td>\n",
       "      <td>0.019414</td>\n",
       "      <td>0.092666</td>\n",
       "      <td>0.073252</td>\n",
       "      <td>22.423285</td>\n",
       "      <td>634.613855</td>\n",
       "      <td>0.892193</td>\n",
       "      <td>0.513724</td>\n",
       "      <td>...</td>\n",
       "      <td>0.066009</td>\n",
       "      <td>0.107937</td>\n",
       "      <td>0.015826</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.009014</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.054688</td>\n",
       "      <td>0.046875</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.077316</td>\n",
       "      <td>0.083829</td>\n",
       "      <td>0.036718</td>\n",
       "      <td>0.008701</td>\n",
       "      <td>0.131908</td>\n",
       "      <td>0.123207</td>\n",
       "      <td>30.757155</td>\n",
       "      <td>1024.927705</td>\n",
       "      <td>0.846389</td>\n",
       "      <td>0.478905</td>\n",
       "      <td>...</td>\n",
       "      <td>0.077316</td>\n",
       "      <td>0.098706</td>\n",
       "      <td>0.015656</td>\n",
       "      <td>0.271186</td>\n",
       "      <td>0.007990</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.046512</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.151228</td>\n",
       "      <td>0.072111</td>\n",
       "      <td>0.158011</td>\n",
       "      <td>0.096582</td>\n",
       "      <td>0.207955</td>\n",
       "      <td>0.111374</td>\n",
       "      <td>1.232831</td>\n",
       "      <td>4.177296</td>\n",
       "      <td>0.963322</td>\n",
       "      <td>0.727232</td>\n",
       "      <td>...</td>\n",
       "      <td>0.151228</td>\n",
       "      <td>0.088965</td>\n",
       "      <td>0.017798</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.201497</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.562500</td>\n",
       "      <td>0.554688</td>\n",
       "      <td>0.247119</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.135120</td>\n",
       "      <td>0.079146</td>\n",
       "      <td>0.124656</td>\n",
       "      <td>0.078720</td>\n",
       "      <td>0.206045</td>\n",
       "      <td>0.127325</td>\n",
       "      <td>1.101174</td>\n",
       "      <td>4.333713</td>\n",
       "      <td>0.971955</td>\n",
       "      <td>0.783568</td>\n",
       "      <td>...</td>\n",
       "      <td>0.135120</td>\n",
       "      <td>0.106398</td>\n",
       "      <td>0.016931</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.712812</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>5.484375</td>\n",
       "      <td>5.476562</td>\n",
       "      <td>0.208274</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   meanfreq        sd    median       Q25       Q75       IQR       skew  \\\n",
       "0  0.059781  0.064241  0.032027  0.015071  0.090193  0.075122  12.863462   \n",
       "1  0.066009  0.067310  0.040229  0.019414  0.092666  0.073252  22.423285   \n",
       "2  0.077316  0.083829  0.036718  0.008701  0.131908  0.123207  30.757155   \n",
       "3  0.151228  0.072111  0.158011  0.096582  0.207955  0.111374   1.232831   \n",
       "4  0.135120  0.079146  0.124656  0.078720  0.206045  0.127325   1.101174   \n",
       "\n",
       "          kurt    sp.ent       sfm  ...  centroid   meanfun    minfun  \\\n",
       "0   274.402906  0.893369  0.491918  ...  0.059781  0.084279  0.015702   \n",
       "1   634.613855  0.892193  0.513724  ...  0.066009  0.107937  0.015826   \n",
       "2  1024.927705  0.846389  0.478905  ...  0.077316  0.098706  0.015656   \n",
       "3     4.177296  0.963322  0.727232  ...  0.151228  0.088965  0.017798   \n",
       "4     4.333713  0.971955  0.783568  ...  0.135120  0.106398  0.016931   \n",
       "\n",
       "     maxfun   meandom    mindom    maxdom   dfrange   modindx  label  \n",
       "0  0.275862  0.007812  0.007812  0.007812  0.000000  0.000000   male  \n",
       "1  0.250000  0.009014  0.007812  0.054688  0.046875  0.052632   male  \n",
       "2  0.271186  0.007990  0.007812  0.015625  0.007812  0.046512   male  \n",
       "3  0.250000  0.201497  0.007812  0.562500  0.554688  0.247119   male  \n",
       "4  0.266667  0.712812  0.007812  5.484375  5.476562  0.208274   male  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "af8c9217",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "28426998",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f3652367",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>meanfreq</th>\n",
       "      <th>sd</th>\n",
       "      <th>median</th>\n",
       "      <th>Q25</th>\n",
       "      <th>Q75</th>\n",
       "      <th>IQR</th>\n",
       "      <th>skew</th>\n",
       "      <th>kurt</th>\n",
       "      <th>sp.ent</th>\n",
       "      <th>sfm</th>\n",
       "      <th>mode</th>\n",
       "      <th>centroid</th>\n",
       "      <th>meanfun</th>\n",
       "      <th>minfun</th>\n",
       "      <th>maxfun</th>\n",
       "      <th>meandom</th>\n",
       "      <th>mindom</th>\n",
       "      <th>maxdom</th>\n",
       "      <th>dfrange</th>\n",
       "      <th>modindx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3168.000000</td>\n",
       "      <td>3168.000000</td>\n",
       "      <td>3168.000000</td>\n",
       "      <td>3168.000000</td>\n",
       "      <td>3168.000000</td>\n",
       "      <td>3168.000000</td>\n",
       "      <td>3168.000000</td>\n",
       "      <td>3168.000000</td>\n",
       "      <td>3168.000000</td>\n",
       "      <td>3168.000000</td>\n",
       "      <td>3168.000000</td>\n",
       "      <td>3168.000000</td>\n",
       "      <td>3168.000000</td>\n",
       "      <td>3168.000000</td>\n",
       "      <td>3168.000000</td>\n",
       "      <td>3168.000000</td>\n",
       "      <td>3168.000000</td>\n",
       "      <td>3168.000000</td>\n",
       "      <td>3168.000000</td>\n",
       "      <td>3168.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.180907</td>\n",
       "      <td>0.057126</td>\n",
       "      <td>0.185621</td>\n",
       "      <td>0.140456</td>\n",
       "      <td>0.224765</td>\n",
       "      <td>0.084309</td>\n",
       "      <td>3.140168</td>\n",
       "      <td>36.568461</td>\n",
       "      <td>0.895127</td>\n",
       "      <td>0.408216</td>\n",
       "      <td>0.165282</td>\n",
       "      <td>0.180907</td>\n",
       "      <td>0.142807</td>\n",
       "      <td>0.036802</td>\n",
       "      <td>0.258842</td>\n",
       "      <td>0.829211</td>\n",
       "      <td>0.052647</td>\n",
       "      <td>5.047277</td>\n",
       "      <td>4.994630</td>\n",
       "      <td>0.173752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.029918</td>\n",
       "      <td>0.016652</td>\n",
       "      <td>0.036360</td>\n",
       "      <td>0.048680</td>\n",
       "      <td>0.023639</td>\n",
       "      <td>0.042783</td>\n",
       "      <td>4.240529</td>\n",
       "      <td>134.928661</td>\n",
       "      <td>0.044980</td>\n",
       "      <td>0.177521</td>\n",
       "      <td>0.077203</td>\n",
       "      <td>0.029918</td>\n",
       "      <td>0.032304</td>\n",
       "      <td>0.019220</td>\n",
       "      <td>0.030077</td>\n",
       "      <td>0.525205</td>\n",
       "      <td>0.063299</td>\n",
       "      <td>3.521157</td>\n",
       "      <td>3.520039</td>\n",
       "      <td>0.119454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.039363</td>\n",
       "      <td>0.018363</td>\n",
       "      <td>0.010975</td>\n",
       "      <td>0.000229</td>\n",
       "      <td>0.042946</td>\n",
       "      <td>0.014558</td>\n",
       "      <td>0.141735</td>\n",
       "      <td>2.068455</td>\n",
       "      <td>0.738651</td>\n",
       "      <td>0.036876</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.039363</td>\n",
       "      <td>0.055565</td>\n",
       "      <td>0.009775</td>\n",
       "      <td>0.103093</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.004883</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.163662</td>\n",
       "      <td>0.041954</td>\n",
       "      <td>0.169593</td>\n",
       "      <td>0.111087</td>\n",
       "      <td>0.208747</td>\n",
       "      <td>0.042560</td>\n",
       "      <td>1.649569</td>\n",
       "      <td>5.669547</td>\n",
       "      <td>0.861811</td>\n",
       "      <td>0.258041</td>\n",
       "      <td>0.118016</td>\n",
       "      <td>0.163662</td>\n",
       "      <td>0.116998</td>\n",
       "      <td>0.018223</td>\n",
       "      <td>0.253968</td>\n",
       "      <td>0.419828</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>2.070312</td>\n",
       "      <td>2.044922</td>\n",
       "      <td>0.099766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.184838</td>\n",
       "      <td>0.059155</td>\n",
       "      <td>0.190032</td>\n",
       "      <td>0.140286</td>\n",
       "      <td>0.225684</td>\n",
       "      <td>0.094280</td>\n",
       "      <td>2.197101</td>\n",
       "      <td>8.318463</td>\n",
       "      <td>0.901767</td>\n",
       "      <td>0.396335</td>\n",
       "      <td>0.186599</td>\n",
       "      <td>0.184838</td>\n",
       "      <td>0.140519</td>\n",
       "      <td>0.046110</td>\n",
       "      <td>0.271186</td>\n",
       "      <td>0.765795</td>\n",
       "      <td>0.023438</td>\n",
       "      <td>4.992188</td>\n",
       "      <td>4.945312</td>\n",
       "      <td>0.139357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.199146</td>\n",
       "      <td>0.067020</td>\n",
       "      <td>0.210618</td>\n",
       "      <td>0.175939</td>\n",
       "      <td>0.243660</td>\n",
       "      <td>0.114175</td>\n",
       "      <td>2.931694</td>\n",
       "      <td>13.648905</td>\n",
       "      <td>0.928713</td>\n",
       "      <td>0.533676</td>\n",
       "      <td>0.221104</td>\n",
       "      <td>0.199146</td>\n",
       "      <td>0.169581</td>\n",
       "      <td>0.047904</td>\n",
       "      <td>0.277457</td>\n",
       "      <td>1.177166</td>\n",
       "      <td>0.070312</td>\n",
       "      <td>7.007812</td>\n",
       "      <td>6.992188</td>\n",
       "      <td>0.209183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.251124</td>\n",
       "      <td>0.115273</td>\n",
       "      <td>0.261224</td>\n",
       "      <td>0.247347</td>\n",
       "      <td>0.273469</td>\n",
       "      <td>0.252225</td>\n",
       "      <td>34.725453</td>\n",
       "      <td>1309.612887</td>\n",
       "      <td>0.981997</td>\n",
       "      <td>0.842936</td>\n",
       "      <td>0.280000</td>\n",
       "      <td>0.251124</td>\n",
       "      <td>0.237636</td>\n",
       "      <td>0.204082</td>\n",
       "      <td>0.279114</td>\n",
       "      <td>2.957682</td>\n",
       "      <td>0.458984</td>\n",
       "      <td>21.867188</td>\n",
       "      <td>21.843750</td>\n",
       "      <td>0.932374</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          meanfreq           sd       median          Q25          Q75  \\\n",
       "count  3168.000000  3168.000000  3168.000000  3168.000000  3168.000000   \n",
       "mean      0.180907     0.057126     0.185621     0.140456     0.224765   \n",
       "std       0.029918     0.016652     0.036360     0.048680     0.023639   \n",
       "min       0.039363     0.018363     0.010975     0.000229     0.042946   \n",
       "25%       0.163662     0.041954     0.169593     0.111087     0.208747   \n",
       "50%       0.184838     0.059155     0.190032     0.140286     0.225684   \n",
       "75%       0.199146     0.067020     0.210618     0.175939     0.243660   \n",
       "max       0.251124     0.115273     0.261224     0.247347     0.273469   \n",
       "\n",
       "               IQR         skew         kurt       sp.ent          sfm  \\\n",
       "count  3168.000000  3168.000000  3168.000000  3168.000000  3168.000000   \n",
       "mean      0.084309     3.140168    36.568461     0.895127     0.408216   \n",
       "std       0.042783     4.240529   134.928661     0.044980     0.177521   \n",
       "min       0.014558     0.141735     2.068455     0.738651     0.036876   \n",
       "25%       0.042560     1.649569     5.669547     0.861811     0.258041   \n",
       "50%       0.094280     2.197101     8.318463     0.901767     0.396335   \n",
       "75%       0.114175     2.931694    13.648905     0.928713     0.533676   \n",
       "max       0.252225    34.725453  1309.612887     0.981997     0.842936   \n",
       "\n",
       "              mode     centroid      meanfun       minfun       maxfun  \\\n",
       "count  3168.000000  3168.000000  3168.000000  3168.000000  3168.000000   \n",
       "mean      0.165282     0.180907     0.142807     0.036802     0.258842   \n",
       "std       0.077203     0.029918     0.032304     0.019220     0.030077   \n",
       "min       0.000000     0.039363     0.055565     0.009775     0.103093   \n",
       "25%       0.118016     0.163662     0.116998     0.018223     0.253968   \n",
       "50%       0.186599     0.184838     0.140519     0.046110     0.271186   \n",
       "75%       0.221104     0.199146     0.169581     0.047904     0.277457   \n",
       "max       0.280000     0.251124     0.237636     0.204082     0.279114   \n",
       "\n",
       "           meandom       mindom       maxdom      dfrange      modindx  \n",
       "count  3168.000000  3168.000000  3168.000000  3168.000000  3168.000000  \n",
       "mean      0.829211     0.052647     5.047277     4.994630     0.173752  \n",
       "std       0.525205     0.063299     3.521157     3.520039     0.119454  \n",
       "min       0.007812     0.004883     0.007812     0.000000     0.000000  \n",
       "25%       0.419828     0.007812     2.070312     2.044922     0.099766  \n",
       "50%       0.765795     0.023438     4.992188     4.945312     0.139357  \n",
       "75%       1.177166     0.070312     7.007812     6.992188     0.209183  \n",
       "max       2.957682     0.458984    21.867188    21.843750     0.932374  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0527e210",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "meanfreq    0\n",
       "sd          0\n",
       "median      0\n",
       "Q25         0\n",
       "Q75         0\n",
       "IQR         0\n",
       "skew        0\n",
       "kurt        0\n",
       "sp.ent      0\n",
       "sfm         0\n",
       "mode        0\n",
       "centroid    0\n",
       "meanfun     0\n",
       "minfun      0\n",
       "maxfun      0\n",
       "meandom     0\n",
       "mindom      0\n",
       "maxdom      0\n",
       "dfrange     0\n",
       "modindx     0\n",
       "label       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "80c367d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "Data=dataset.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "eab7d3ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = dataset.iloc[:, :-1]\n",
    "y = dataset.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "490bbc44",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "label_encoder = label_encoder.fit(y)\n",
    "label_encoded_y = label_encoder.transform(y)\n",
    "test_size = 0.33\n",
    "seed = 7\n",
    "x_training, x_test, y_training, y_test = train_test_split(x,\n",
    "                                                          label_encoded_y,\n",
    "                                                          test_size=test_size,\n",
    "                                                          random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0996745c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ahmad\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:18:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Accuracy XGBoost: 97.51%\n"
     ]
    }
   ],
   "source": [
    "# XGBoost\n",
    "model = XGBClassifier()\n",
    "model.fit(x_training, y_training)\n",
    "y_pred = model.predict(x_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy XGBoost: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dbbc6843",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy LightGBM: 97.99%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ahmad\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    }
   ],
   "source": [
    "# LightGBM\n",
    "import lightgbm as lgb\n",
    "lgb_train = lgb.Dataset(x_training, y_training)\n",
    "lgb_eval = lgb.Dataset(x_test, y_test, reference=lgb_train)\n",
    "params = {\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'binary',\n",
    "    'metric': 'binary_logloss',\n",
    "    'verbose': -1\n",
    "}\n",
    "\n",
    "gbm = lgb.train(params,\n",
    "                lgb_train,\n",
    "                verbose_eval=False,\n",
    "                valid_sets=lgb_eval)\n",
    "\n",
    "y_pred = gbm.predict(x_test, num_iteration=gbm.best_iteration)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred.round())\n",
    "\n",
    "print(\"Accuracy LightGBM: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "448a9d0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "67/67 [==============================] - 1s 4ms/step - loss: 0.8546 - accuracy: 0.5146 - val_loss: 0.6625 - val_accuracy: 0.6864\n",
      "Epoch 2/30\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.6748 - accuracy: 0.6352 - val_loss: 0.6276 - val_accuracy: 0.6052\n",
      "Epoch 3/30\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.6428 - accuracy: 0.6621 - val_loss: 0.6190 - val_accuracy: 0.6874\n",
      "Epoch 4/30\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.6703 - accuracy: 0.6857 - val_loss: 0.5841 - val_accuracy: 0.7696\n",
      "Epoch 5/30\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.6025 - accuracy: 0.7130 - val_loss: 0.5538 - val_accuracy: 0.7677\n",
      "Epoch 6/30\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.5719 - accuracy: 0.7441 - val_loss: 0.5288 - val_accuracy: 0.7935\n",
      "Epoch 7/30\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.5619 - accuracy: 0.7601 - val_loss: 0.5186 - val_accuracy: 0.7639\n",
      "Epoch 8/30\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.5445 - accuracy: 0.7644 - val_loss: 0.5249 - val_accuracy: 0.7792\n",
      "Epoch 9/30\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.5305 - accuracy: 0.7733 - val_loss: 0.4797 - val_accuracy: 0.8289\n",
      "Epoch 10/30\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.5504 - accuracy: 0.7752 - val_loss: 0.4981 - val_accuracy: 0.7964\n",
      "Epoch 11/30\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.5162 - accuracy: 0.7837 - val_loss: 0.4583 - val_accuracy: 0.7801\n",
      "Epoch 12/30\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.4913 - accuracy: 0.7997 - val_loss: 0.4260 - val_accuracy: 0.8528\n",
      "Epoch 13/30\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.5070 - accuracy: 0.8073 - val_loss: 0.4116 - val_accuracy: 0.8585\n",
      "Epoch 14/30\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.4729 - accuracy: 0.8110 - val_loss: 0.3940 - val_accuracy: 0.8623\n",
      "Epoch 15/30\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.4733 - accuracy: 0.8195 - val_loss: 0.3840 - val_accuracy: 0.8671\n",
      "Epoch 16/30\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.4561 - accuracy: 0.8308 - val_loss: 0.3984 - val_accuracy: 0.8499\n",
      "Epoch 17/30\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.4223 - accuracy: 0.8336 - val_loss: 0.3706 - val_accuracy: 0.8671\n",
      "Epoch 18/30\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.4130 - accuracy: 0.8440 - val_loss: 0.3701 - val_accuracy: 0.8595\n",
      "Epoch 19/30\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.3985 - accuracy: 0.8506 - val_loss: 0.3466 - val_accuracy: 0.8834\n",
      "Epoch 20/30\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.3975 - accuracy: 0.8478 - val_loss: 0.4229 - val_accuracy: 0.8011\n",
      "Epoch 21/30\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.3813 - accuracy: 0.8600 - val_loss: 0.3482 - val_accuracy: 0.8748\n",
      "Epoch 22/30\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.3757 - accuracy: 0.8591 - val_loss: 0.3206 - val_accuracy: 0.8977\n",
      "Epoch 23/30\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.3574 - accuracy: 0.8680 - val_loss: 0.3166 - val_accuracy: 0.8977\n",
      "Epoch 24/30\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.3475 - accuracy: 0.8685 - val_loss: 0.3226 - val_accuracy: 0.8767\n",
      "Epoch 25/30\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.3488 - accuracy: 0.8761 - val_loss: 0.2903 - val_accuracy: 0.9082\n",
      "Epoch 26/30\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.3267 - accuracy: 0.8779 - val_loss: 0.3485 - val_accuracy: 0.8767\n",
      "Epoch 27/30\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.3251 - accuracy: 0.8812 - val_loss: 0.2858 - val_accuracy: 0.9101\n",
      "Epoch 28/30\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.3297 - accuracy: 0.8888 - val_loss: 0.2831 - val_accuracy: 0.9015\n",
      "Epoch 29/30\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.3062 - accuracy: 0.8874 - val_loss: 0.2872 - val_accuracy: 0.8977\n",
      "Epoch 30/30\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.3171 - accuracy: 0.8893 - val_loss: 0.2514 - val_accuracy: 0.9149\n"
     ]
    }
   ],
   "source": [
    "# Neural Network\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(20*2, input_dim=x_training.shape[1], activation='relu'))\n",
    "model.add(Dense(20, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(x_training, y_training, epochs=30, verbose=1, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8afb6e09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9149139523506165\n"
     ]
    }
   ],
   "source": [
    "print(history.history['val_accuracy'][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1958e13",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
